\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{schwab20164th}
\citation{lippmann1987introduction}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}INTRODUCTION}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}}
\citation{dalcin2011parallel}
\citation{stanley2002evolving}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Question}{2}{section.1.2}}
\citation{dalcin2011parallel}
\citation{lippmann1987introduction}
\citation{hopfield1985neural}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Research Objectives}{3}{section.1.3}}
\citation{goh1995back}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Biological vs Artificial Neuron, \href  {https://54e779d2-a-62cb3a1a-s-sites.googlegroups.com/site/mrstevensonstechclassroom/hl-topics-only/4a-robotics-ai/neural-networks-computational-intelligence/Biological\%20vs\%20artificial\%20neuron.jpeg?attachauth=ANoY7cqMmj19FWvS5ZScxTm4AYPR7gp5OXR8mmegEe9VdE5N2pO_7KVYIA_oniPAsFBdG_Z2KIOIWWMZIhueb0m5EFIoE31mK9gl8UStTgYLeAyrMAYuqpNBTyGdRVSjx_5SgesKiyCP6wWhHptFr9_AhsTsXxuZbEjkCw45qyENjz2llQT8Fj-_vvPAnt8UyFXctSyLwadVcdv31CTNlLbjmLz6dekyA0aUR34gQMcoUMypraP9PlWZx988r4oOQzzQ2IbtD2JhHN5WZ42oww3UPK_Fk_otT5BmPieFdvAHXNuxX4MjEvV43HMsqAtfEJoLH1CC-mtDt94MsNARnSe_CJ7SrOSp9_EyuK_oSf_JLUQfRvBUwMM\%3D&attredirects=0}{source}\relax }}{4}{figure.caption.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Theory}{4}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Aspects of Neural Network}{4}{subsection.1.4.1}}
\citation{werbos1974beyond}
\citation{goodfellow2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Simple Neural Network vs Deep Learning Neural Network, \href  {https://i.stack.imgur.com/OH3gI.png}{source} \relax }}{5}{figure.caption.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Graphical Depiction of Multilayer Perceptrons\relax }}{6}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Graphical Depiction of Convolutional Neural Networks\relax }}{6}{figure.caption.7}}
\citation{darwin2004origin}
\citation{mitchell1998introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Survival of the fittest}{7}{subsection.1.4.2}}
\citation{whitley1994genetic}
\citation{masel2011genetic}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Types of crossover, \href  {https://www.researchgate.net/publication/268525551_Genetic_Algorithms_in_Wireless_Networking_Techniques_Applications_and_Issues/figures?lo=1}{source} \relax }}{8}{figure.caption.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Quantum Computation}{9}{subsection.1.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Overview}{9}{section.1.5}}
\citation{bergstra2012random}
\citation{hsu2003practical}
\citation{chicco2017ten}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}STATE OF THE ART}{11}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}A review of Neural Networks Optimization Procedure}{11}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Types of tuning: }{11}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Hand Tuning}{11}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Grid Search Method}{11}{subsection.2.1.1}}
\citation{bergstra2012random}
\citation{solis1981minimization}
\citation{snoek2012practical}
\citation{jaderberg2017population}
\citation{srinivas2009gaussian}
\citation{domhan2015speeding}
\citation{gonzalez2016batch}
\citation{feurer2015efficient}
\@writefile{toc}{\contentsline {subsubsection}{Random Search (RS) Method}{12}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Bayesian Optimization Method}{12}{subsection.2.1.1}}
\citation{larsen1996design}
\citation{maclaurin2015gradient}
\citation{bergstra2011algorithms}
\citation{varetto1998genetic}
\citation{varetto1998genetic}
\citation{manikas2007genetic}
\citation{gen1997genetic}
\citation{DEvol}
\citation{DEAP_JMLR2012}
\@writefile{toc}{\contentsline {subsubsection}{Gradient based optimization}{13}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Evolution-based optimization}{13}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Evolutionary based optimization \IeC {\textendash } A perspective}{13}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{DEvol and DEAP}{13}{subsection.2.1.2}}
\citation{olson2016automating}
\citation{olson2016evaluation}
\citation{jaderberg2017population}
\citation{shor1999polynomial}
\citation{udrescu2006implementing}
\@writefile{toc}{\contentsline {subsubsection}{TPOT}{14}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{PBT}{14}{figure.caption.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Machine Learning Process using TPOT, \href  {https://media.springernature.com/original/springer-static/image/chp\%3A10.1007\%2F978-3-319-31204-0_9/MediaObjects/419269_1_En_9_Fig1_HTML.gif}{source}\relax }}{15}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces TPOT, \href  {https://media.springernature.com/original/springer-static/image/chp\%3A10.1007\%2F978-3-319-31204-0_9/MediaObjects/419269_1_En_9_Fig2_HTML.gif}{source}\relax }}{15}{figure.caption.10}}
\citation{wang2005hybrid}
\citation{gonccalves2005hybrid}
\citation{kim2007hybrid}
\citation{kao2008hybrid}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Population Based Training of Neural Networks, \href  {https://www.semanticscholar.org/paper/Population-Based-Training-of-Neural-Networks-Jaderberg-Dalibard/7a0b1f7fe39629360f1766a480dd8903065a2854/figure/0}{source}\relax }}{16}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Quantum Inspired Genetic algorithm}{16}{subsection.2.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Overview}{16}{subsection.2.1.4}}
\citation{cantu1998survey}
\citation{insidehpc}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}DESIGN}{17}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.1}The framework}{17}{subsection.3.0.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Architecture Optimization Algorithm\relax }}{18}{figure.caption.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Architecture for EETO for Neural Network Tuning\relax }}{19}{figure.caption.13}}
\citation{pypy}
\citation{pyrexDocumentation}
\citation{pyrexLimitations}
\citation{pythonDocumentation}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Island Model, \href  {https://www.researchgate.net/publication/284723071_Parallel_Genetic_Algorithms_on_a_GPU_to_Solve_the_Travelling_Salesman_Problem/figures?lo=1}{source}\relax }}{20}{figure.caption.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.2}Software development}{20}{subsection.3.0.2}}
\citation{dalcin2008mpi}
\citation{chollet2015keras}
\citation{almasi1988highly}
\citation{hwu2014ahead}
\citation{kumar1994introduction}
\@writefile{toc}{\contentsline {subsubsection}{Handling of SLURM workload manager}{21}{subsection.3.0.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.3}Leveraging Parallel Computing}{21}{subsection.3.0.3}}
\citation{li2007efficient}
\citation{marakeby2013analysis}
\citation{wahib2011optimization}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Architecture for Parallel Neural Network Tuning\relax }}{23}{figure.caption.15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}HPC Cluster Architecture: Clusters, Installations}{24}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Development: Using Chuck Cluster}{24}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Deployment Trial 1: Using Lonsdale Cluster}{24}{subsection.3.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Steps on TCHPC Chuck Cluster\relax }}{25}{figure.caption.16}}
\citation{TCHPC_clusters}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Deployment Trial 2: Using Kelvin Cluster}{26}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Deployment Trial 3: Using Boyle Cluster}{26}{subsection.3.1.4}}
\gdef \LT@i {\LT@entry 
    {1}{161.01955pt}\LT@entry 
    {1}{197.37544pt}\LT@entry 
    {1}{196.0702pt}\LT@entry 
    {1}{198.0702pt}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Installation steps}{28}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Introduction to the code for Simulation }{28}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Steps to install libraries\relax }}{29}{figure.caption.17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sequential Concern}{33}{section.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{SSE Speed Limitations}{33}{section.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{Training Speed Constraint}{33}{section.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}IMPLEMENTATION AND DATA ANALYSIS}{34}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Genetics Inspired Exploration vs Exploitation based Optimization for Neural Network Tuning}{34}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Implementation}{34}{subsection.4.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Cross tab of activation functions and optimizers tested \relax }}{35}{figure.caption.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Analysis}{35}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Sampled hyper-parameters' set; \newline  Column 1 (from Left to Right): Activation function, Optimizer, Layers, Neurons, Dropout; \newline  Column 2: Maximum Fitness for the hyper-parameter combination;\relax }}{36}{figure.caption.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Fitness Heat Map - neurons va layers\relax }}{37}{figure.caption.20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}PGA Inspired Exploration vs Exploitation based Optimization for Neural Network Tuning}{37}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Implementation}{37}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Comparative Analysis}{38}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{Island Model}{39}{figure.caption.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Fitness comparison - Sequential vs Parallel Implementation;\newline  Left Hand Side: Fitness results for Sequential Implementation with different network sizes;\newline  Right Hand Side: Fitness results for Parallel Implementation with different network sizes; \newline  Top to bottom: Fitness evaluation graphs for Network sizes 4, 6, 8, 10, 12; \newline  Fitness are being captured at generation level;\relax }}{40}{figure.caption.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Time comparison - Sequential vs Parallel Implementation\newline  Left Hand Side: Results for time taken in Sequential Implementation with different network sizes;\newline  Right Hand Side: Results for time taken in Parallel Implementation with different network sizes; \newline  Top to bottom: Graph depicting Time Taken for Network sizes 4, 6, 8, 10, 12; \newline  Area graph for Time taken is shown at generation level;\relax }}{41}{figure.caption.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Time comparison - Sequential vs Parallel vs Island Implementation; \newline  Legend Decode: \newline  \textbf  {4s} -> 4 Networks Genetics Inspired Algorithm Data; \newline  \textbf  {4p} -> 4 Networks Parallel Algorithm Data; \newline  \textbf  {Island\_ID0} -> 4 Networks Genetic Algorithm Island Algorithm Data using only one Island group with ID "0"\relax }}{42}{figure.caption.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Speed-up and Efficiency\relax }}{44}{figure.caption.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Memory leak Snapshots\relax }}{45}{figure.caption.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Memory leak with generations\relax }}{45}{figure.caption.26}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Quantum Genetics Inspired Genetics Inspired Exploration vs Exploitation based Optimization for Neural Network Tuning}{47}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Best fitness achieved - for every generation for various network sizes; \newline  Legend Decode: \newline  4q -> 4 Networks Quantum Inspired Algorithm Data; \newline  6q -> 6 Networks Quantum Inspired Algorithm Data;\newline  8q -> 8 Networks Quantum Inspired Algorithm Data; \newline  10q -> 10 Networks Quantum Inspired Algorithm Data; \newline  12q -> 12 Networks Quantum Inspired Algorithm Data; \relax }}{48}{figure.caption.27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces The graph shows time taken and fitness comparison taking 4 networks \newline  a. the time taken in both Parallel vs Quantum Inspired Algorithm implementations \newline  b. best fitness for every generation in both Parallel vs Quantum Inspired Algorithm implementations \relax }}{49}{figure.caption.28}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Summary}{50}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{unsrtnat}
\bibdata{bibs/sample}
\bibcite{schwab20164th}{{1}{2016}{{Schwab}}{{}}}
\bibcite{lippmann1987introduction}{{2}{1987}{{Lippmann}}{{}}}
\bibcite{dalcin2011parallel}{{3}{2011}{{Dalcin et~al.}}{{Dalcin, Paz, Kler, and Cosimo}}}
\bibcite{stanley2002evolving}{{4}{2002}{{Stanley and Miikkulainen}}{{}}}
\bibcite{hopfield1985neural}{{5}{1985}{{Hopfield and Tank}}{{}}}
\bibcite{goh1995back}{{6}{1995}{{Goh}}{{}}}
\bibcite{werbos1974beyond}{{7}{1974}{{Werbos}}{{}}}
\bibcite{goodfellow2016deep}{{8}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibcite{darwin2004origin}{{9}{2004}{{Darwin}}{{}}}
\bibcite{mitchell1998introduction}{{10}{1998}{{Mitchell}}{{}}}
\bibcite{whitley1994genetic}{{11}{1994}{{Whitley}}{{}}}
\bibcite{masel2011genetic}{{12}{2011}{{Masel}}{{}}}
\bibcite{bergstra2012random}{{13}{2012}{{Bergstra and Bengio}}{{}}}
\bibcite{hsu2003practical}{{14}{2003}{{Hsu et~al.}}{{Hsu, Chang, Lin, et~al.}}}
\bibcite{chicco2017ten}{{15}{2017}{{Chicco}}{{}}}
\bibcite{solis1981minimization}{{16}{1981}{{Solis and Wets}}{{}}}
\bibcite{snoek2012practical}{{17}{2012}{{Snoek et~al.}}{{Snoek, Larochelle, and Adams}}}
\bibcite{jaderberg2017population}{{18}{2017}{{Jaderberg et~al.}}{{Jaderberg, Dalibard, Osindero, Czarnecki, Donahue, Razavi, Vinyals, Green, Dunning, Simonyan, et~al.}}}
\bibcite{srinivas2009gaussian}{{19}{2009}{{Srinivas et~al.}}{{Srinivas, Krause, Kakade, and Seeger}}}
\bibcite{domhan2015speeding}{{20}{2015}{{Domhan et~al.}}{{Domhan, Springenberg, and Hutter}}}
\bibcite{gonzalez2016batch}{{21}{2016}{{Gonz{\'a}lez et~al.}}{{Gonz{\'a}lez, Dai, Hennig, and Lawrence}}}
\bibcite{feurer2015efficient}{{22}{2015}{{Feurer et~al.}}{{Feurer, Klein, Eggensperger, Springenberg, Blum, and Hutter}}}
\bibcite{larsen1996design}{{23}{1996}{{Larsen et~al.}}{{Larsen, Hansen, Svarer, and Ohlsson}}}
\bibcite{maclaurin2015gradient}{{24}{2015}{{Maclaurin et~al.}}{{Maclaurin, Duvenaud, and Adams}}}
\bibcite{bergstra2011algorithms}{{25}{2011}{{Bergstra et~al.}}{{Bergstra, Bardenet, Bengio, and K{\'e}gl}}}
\bibcite{varetto1998genetic}{{26}{1998}{{Varetto}}{{}}}
\bibcite{manikas2007genetic}{{27}{2007}{{Manikas et~al.}}{{Manikas, Ashenayi, and Wainwright}}}
\bibcite{gen1997genetic}{{28}{1997}{{Gen and Cheng}}{{}}}
\bibcite{DEvol}{{29}{2017}{{Davison}}{{}}}
\bibcite{DEAP_JMLR2012}{{30}{2012}{{Fortin et~al.}}{{Fortin, {De Rainville}, Gardner, Parizeau, and Gagn\'e}}}
\bibcite{olson2016automating}{{31}{2016{}}{{Olson et~al.}}{{Olson, Urbanowicz, Andrews, Lavender, Moore, et~al.}}}
\bibcite{olson2016evaluation}{{32}{2016{}}{{Olson et~al.}}{{Olson, Bartley, Urbanowicz, and Moore}}}
\bibcite{shor1999polynomial}{{33}{1999}{{Shor}}{{}}}
\bibcite{udrescu2006implementing}{{34}{2006}{{Udrescu et~al.}}{{Udrescu, Prodan, and Vl{\u {a}}du{\c {t}}iu}}}
\bibcite{wang2005hybrid}{{35}{2005}{{Wang et~al.}}{{Wang, Tang, and Wu}}}
\bibcite{gonccalves2005hybrid}{{36}{2005}{{Gon{\c {c}}alves et~al.}}{{Gon{\c {c}}alves, de~Magalh{\~a}es~Mendes, and Resende}}}
\bibcite{kim2007hybrid}{{37}{2007}{{Kim et~al.}}{{Kim, Abraham, and Cho}}}
\bibcite{kao2008hybrid}{{38}{2008}{{Kao and Zahara}}{{}}}
\bibcite{cantu1998survey}{{39}{1998}{{Cant{\'u}-Paz}}{{}}}
\bibcite{insidehpc}{{40}{2017}{{Friedman}}{{}}}
\bibcite{pypy}{{41}{}{{pyp}}{{}}}
\bibcite{pyrexDocumentation}{{42}{}{{pyr}}{{}}}
\bibcite{pyrexLimitations}{{43}{}{{pyr}}{{}}}
\bibcite{pythonDocumentation}{{44}{2018}{{pyt}}{{}}}
\bibcite{dalcin2008mpi}{{45}{2008}{{Dalc{\i }n et~al.}}{{Dalc{\i }n, Paz, Storti, and D\IeC {\textquoteright }El{\i }a}}}
\bibcite{chollet2015keras}{{46}{2015}{{Chollet et~al.}}{{}}}
\bibcite{almasi1988highly}{{47}{1988}{{Almasi and Gottlieb}}{{}}}
\bibcite{hwu2014ahead}{{48}{2014}{{Hwu}}{{}}}
\bibcite{kumar1994introduction}{{49}{1994}{{Kumar et~al.}}{{Kumar, Grama, Gupta, and Karypis}}}
\bibcite{li2007efficient}{{50}{2007}{{Li et~al.}}{{Li, Wang, He, and Chi}}}
\bibcite{marakeby2013analysis}{{51}{2013}{{Marakeby}}{{}}}
\bibcite{wahib2011optimization}{{52}{2011}{{Wahib et~al.}}{{Wahib, Munawar, Munetomo, and Akama}}}
\bibcite{liu_schmidt}{{53}{2006}{{Liu and Schmidt}}{{}}}
\bibcite{TCHPC_clusters}{{54}{}{{TCH}}{{}}}
